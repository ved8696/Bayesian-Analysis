---
title: "ADA (week 9) Latent discrete parameters & divergent transitions"
author: "Vedant Shah"
date: "06/13/2020"
output: 
  html_document:
    toc: true
    toc_depth: 2
    highlight: tango
---


```{r setup, include=FALSE}

knitr::opts_chunk$set(echo = TRUE, cache = F, message = FALSE, warning = FALSE, error = FALSE, fig.width = 5, fig.align = "center")

```

```{r libraries, message = FALSE, warning = FALSE, include = FALSE}

# package for convenience functions (e.g. ggplot2, dplyr, etc.)
library(tidyverse)

# package for Bayesian regression modeling
library(brms)

# package for visualization
library(tidybayes)

# package to visualize 
library(bayesplot)

# package to communicate with Stan
library(rstan)

# these options help Stan run faster
options(mc.cores = parallel::detectCores())

#devtools::install_github("michael-franke/aida-package")
library(aida)

# use the aida-theme for plotting
theme_set(theme_aida())

# global color scheme / non-optimized
project_colors = c("#E69F00", "#56B4E9", "#009E73", "#F0E442", "#0072B2", "#D55E00", "#CC79A7", "#000000")

# setting theme colors globally
scale_colour_discrete <- function(...) {
  scale_colour_manual(..., values = project_colors)
}
scale_fill_discrete <- function(...) {
   scale_fill_manual(..., values = project_colors)
} 

```



# Instructions

- Use the file `09-exercises.Rmd`, solve the exercises marked as homework, and save the file with your student number and name.
- ‘Knit’ the document to produce a HTML file.
  - **include the other JS and CSS files that came with the ZIP file for this week in order to produce nicely looking Stan code in the HTML**
- **include the Stan code you write in the Rmarkdow (see example in exercise 1 below), even if you also include a seperate file to run that model from**
- Please do not suppress the code in the HTML-Output!
  - **do suppress the output of Stan by including the flag `results = "hide"` in the r chunk calling the `stan`  function**
- Create a ZIP archive called “MATRIKELNR_Lastname_Firstname_ABDA_Week9.zip” containing:
  - an R Markdown file “MATRIKELNR_Lastname_Firstname_ABDA_Week9.Rmd”
  - a knitted HTML document “MATRIKELNR_Lastname_Firstname_ABDA_Week9.html”
  - **all of your Stan code files**
  - **any pictures you add (of model graphs ...)**
  - **the auxilliary JS and CSS files for syntax highlighting of Stan code**
- Upload the ZIP archive on Stud.IP in the homework folder before the deadline. You may upload as many times as you like before the deadline, only your final submission will count.

# <span style = "color:firebrick">2 [HOMEWORK]:</span> Finite Mixtures

Let's look again (yawn) at our fictitious flower data. We take our measures from before but add 4 to each measure from group B (for educational reasons, as you'll see presently).

```{r}
heights_A <- c(6.94, 11.77, 8.97, 12.2, 8.48, 
               9.29, 13.03, 13.58, 7.63, 11.47, 
               10.24, 8.99, 8.29, 10.01, 9.47, 
               9.92, 6.83, 11.6, 10.29, 10.7, 
               11, 8.68, 11.71, 10.09, 9.7)

heights_B <- c(11.45, 11.89, 13.35, 11.56, 13.78, 
               12.12, 10.41, 11.99, 12.27, 13.43, 
               10.91, 9.13, 9.25, 9.94, 13.5, 
               11.26, 10.38, 13.78, 9.35, 11.67, 
               11.32, 11.98, 12.92, 12.03, 12.02) + 4
```

Here's how this data is distributed:

```{r}
ffm_data <- tibble(
  A = heights_A,
  B = heights_B
) %>% 
  pivot_longer(
    cols      = everything(),
    names_to  = 'species',
    values_to = 'height'
  )

ffm_data %>% 
  ggplot(aes(x = height)) +
  geom_density(aes(color = species), size = 2) +
  geom_rug(aes(color = species), size = 1.5) +
  theme(legend.position = 'none')
```

Now suppose that we get the data like this, without information which measure was from which group:

```{r}
flower_heights <- c(heights_A, heights_B)
tibble(flower_heights) %>% 
  ggplot(aes(x = flower_heights)) + 
  geom_rug(size = 2) +
  geom_density(size = 2)
```

Data may often look like this, showing signs of **bi- or multi-modality**, i.e., having several "humps" or apparent local areas of higher concentration. If we fit a single Gaussian to this data it might look like this:

```{r}
# using the descriptive means/SD for a quick "best fit"
mu    <- mean(flower_heights)
sigma <- sd(flower_heights)
tibble(
  source  = c(rep("data", length(flower_heights)), rep("fit", 1000)),
  height = c(flower_heights, rnorm(1000, mu, sigma))
) %>%  
ggplot(aes(x = height, fill=source)) +
  geom_density(size = 2, alpha = 0.3)


```

We are therefore trying to estimate a Gaussian mixture model (GMM). We take the simplest GMM with just two groups (because we see two "humps", or have *a priori* information that there are exactly two groups; the bonus exercise looks at a generalization to $K>2$ groups). Concretely, for each data point $y_i$, $i \in \{1, \dots, N\}$, we are going to estimate how likely data point $i$ may have been a sample from normal distribution "Number 0", with $\mu_0$ and $\sigma_0$, or from normal distribution "Number 1", with $\mu_1$ and $\sigma_1$. Naturally, all $\mu_{0,1}$ and $\sigma_{0,1}$ are estimated from the data, as are the group-indicator variables $z_i$. There is also a global parameter $p$ which indicates how likely any data point is to come from one of the two distributions (you'll think about which one below!). Here's the full model we will work with (modulo an additional ordering constraint, as discussed below):

$$
\begin{align*}
p        & \sim \text{Beta}(1,1) \\
z_i      & \sim \text{Bernoulli}(p) \\
\mu_{0,1}    & \sim \mathcal{N}(12, 10) \\
\sigma_{0,1} & \sim \text{log-normal}(0, 2) \\
y_i      & \sim \mathcal{N}(\mu_{z_i}, \sigma_{z_i})
\end{align*}
$$

## 2.a Draw the model

Draw a graphical representation of this mixture model, following the conventions outlined [here](https://michael-franke.github.io/intro-data-analysis/Chap-03-03-models-representation.html). You can draw on paper, take a picture, or draw by hand with a mouse in any drawing program (like [this](http://draw.io/)). Maybe use ASCII art. Anything is fine really! This does not need to look pretty. It just needs to be correct. 

![2.a](/Users\User\Desktop\ex2a.jpg)

## 2.b Run the model & interpret the output

We are going to pack the data together for fitting the Stan model:

```{r}
data_GMM <- list(
  y = flower_heights,
  N = length(flower_heights)
)
```

Below is the Stan code for this model. It is also given in file `ADA-W09-Ex2b-GMM.stan`. A few comments on this code:

1. There is no occurrence of variable $z_i$, as this is marginalized out. We do this following the same recipe as before and increment the log-score manually, using `target += log_sum_exp(alpha)`.
2. We declare vector `mu` to be of a particular type which we have not seen before. We want the vector to be ordered. We will come back to this later. Don't worry about it now.

```{stan, output.var="Ex2b-GMM", eval = F}
data {
  int<lower=1> N; 
  real y[N];      
}
parameters {
  real<lower=0,upper=1> p;         
  ordered[2] mu;             
  vector<lower=0>[2] sigma; 
}
model {
  p ~ beta(1,1);
  mu ~ normal(12, 10);
  sigma ~ lognormal(0, 1);
  for (i in 1:N) {
    vector[2] alpha;
    alpha[1] = log(p)   + normal_lpdf(y[i] | mu[1], sigma[1]);
    alpha[2] = log(1-p) + normal_lpdf(y[i] | mu[2], sigma[2]);
    target += log_sum_exp(alpha);
  }
}
```


```{r, results="hide"}
stan_fit_2b_GMM <- stan(
  file = 'ADA-W09-Ex2b-GMM.stan',
  data = data_GMM
)
```

```{r}
stan_fit_2b_GMM
```

Interpret this outcome! Focus on parameters $p$, $\mu_1$ and $\mu_2$. What does $p$ capture in this implementation? Do the (mean) estimated values make sense?

**Solution:**

<span style = "color:firebrick"> The mean of the both the groups indicate a considerable difference in the both the groups. the $p$ value indicates how likely a data point is from one of the distributions. $p\approx$  0.54 is showing that the values that much likely to come from group A compared to group B. The value is actually really close to 0.5 which indicated 50 percent probability of the data point being from any distribution. The mean estimation makes sense as the mean estimation is closely equal to the mean of the original data points provided per distribution. So given the gaussian mixture model, it is able to estimate mean which is very close to the actual mean of the data points provided.  </span>

## 2.c An unidentifiable model

Let's run the model in file `ADA-W09-Ex2c-GMM.stan`, which is exactly the same as before but with vector `mu` being an unordered vector of reals. 

```{r, results="hide"}
stan_fit_2c_GMM <- stan(
  file = 'ADA-W09-Ex2c-GMM.stan',
  data = data_GMM,
  # set a seed for reproducible results
  seed = 1734
)
```

Here's a summary of the outcome:

```{r}
stan_fit_2c_GMM
```

Tell us what is remarkable here and explain why this happened. Explain in what sense this model is "unidentifiable".

**Hint:** Explore the parameters with high $\hat{R}$ values. When a model fit seems problematic, a nice tool to explore what might be amiss is the package `shinystan`. You could do this:

```{r, eval = F}
shinystan::launch_shinystan(stan_fit_2c_GMM)
```

Then head over to the tab "Explore" and have a look at some of the parameters.

**Solution:**

<span style = "color:firebrick">The remarkable part is the mean estimation. As the $p$ = 0.5 the model assumes that the data point can be from any distribution.Also the data points are unordered, the means of the data point takes complete data set as their likelihood. So the 2 means are representing means from the compelete dataset rather than having the understanding of the ordered dataset. The model is "unidentifiable" as the estimations is not indicating or we do not learn about the true values of the models underlying parameter. After obtaining a posterior, it should thereotically help us to understand the true values. This model does not fullfill that requirement hence it is unidentifiable </span>

## 2.d Posterior predictive check

Extend the model from 2b to also output samples from the posterior predictive distribution. Save your code in a file `ADA-W09-Ex2d-GMM.stan`. Run the model, collect the posterior predictive samples in a variable called `yrep` and draw a density plot. Does this look like a distribution that could have generated the data? You can use the code below once the model is coded up.

```{r, results="hide", eval = F}
stan_fit_2d_GMM <- stan(
  file = 'ADA-W09-Ex2d-GMM.stan',
  data = data_GMM,
  # only return the posterior predictive samples
  pars = c('yrep')
)

stan_fit_2d_GMM
```

```{r, eval = F}
tibble(
  source  = c(rep("data", length(flower_heights)), rep("PostPred", length(extract(stan_fit_2d_GMM)$yrep))),
  height = c(flower_heights, extract(stan_fit_2d_GMM)$yrep)
) %>%  
ggplot(aes(x = height, fill=source)) +
  geom_density(size = 2, alpha = 0.3)
%>% density() %>% plot()
```

**Solution:**

<span style = "color:firebrick"> The posterior distribution is not exactly similiar to the original data.There is a clear difference in the density of the values which are more concentrated towards the estimation compared to the actualt data.   However, the mean estimations and sigma estimations we got in 2b is generated by this distribution which is similiar to the mean of the actual data. </span>

## 2.e Using BRMS

We can also run this finite mixture model in `brms`. We saw earlier already that fitting the paramters of a single Gaussian is like fitting an intercept-only simple linear regression model. We can add finite mixtures to `brms` like so (the syntax for creating mixtures is not so important for us right now):

```{r, results = "hide"}
brms_fit_2e_GMM <- brm(
  # intercept only model
  formula = y ~ 1, 
  data = data_GMM, 
  # declare that the likelihood should be a mixture
  family = mixture(gaussian, gaussian),
  # use weakly informative priors on mu  
  prior = c(
    prior(normal(12, 10), Intercept, dpar = mu1),
    prior(normal(12, 10), Intercept, dpar = mu2)
  )
) 
```

Let's look at the model fit:

```{r}
brms_fit_2e_GMM
```

Let's also look at the Stan code that `brms` produced in the background for this model in order to find out how this model is related to that of Ex 2.b:

```{r}
brms_fit_2e_GMM$model
```

Now, your job. Look at the two previous outputs and answer the following questions:

- Is the `brms`-model the exact same as the model in Ex 2.b?
- What is the equivalent of the variable `alpha` from the model of Ex 2.b in this new `brms`-generated code?
- What is the equivalent of the variable `p` from the model of Ex 2.b in this new `brms`-generated code?
- Is the `brms` code generating posterior predictive samples?
- What is the prior probability in the `brms`-generated model of any given data point $y_i$ to be from the first or second mixture component? Can you even tell from the code?
  
**Solution:**
<span style = "color:firebrick">
1) the models have a similiar parameters struture but the model is not the same.
2) the parameter ps is the equivalent to alpha from the model 2.b
3) the parameter theta is equal to p from the model 2.b
4) The generated quantities block is generating the intercepts of the linear predicitve model and not the posterior predictive samples. 
5) the function dirichlet_lpdf with parameter theta and con_theta is the prior probability in this model. the theta represents the mixing proprotions and con_theta the prior concentration.  </span>


# <span style = "color:firebrick">3 [HOMEWORK]:</span> Divergent transitions, and how to tame (at least some of) them

The "eight schools" example is a classic and a simple illustration of a **hierarchical model**. There are $N =8$ pairs of observations, each pair from a different school. For each school $i$, we have an estimated effect size $y_i$ and an estimated standard error $\sigma_i$ for the reported effect size. (The experiments conducted at each school which gave us these pairs investigated whether short-term coaching has a effect on SAT scores.)

```{r}
data_eight_schools <- list(
  N = 8, 
  y = c(28,  8, -3,  7, -1,  1, 18, 12),
  sigma = c(15, 10, 16, 11,  9, 11, 10, 18)
)
```

We are interested in inferring the latent true effect size $\theta_i$ for each school $i$ that could have generated the observed effect size $y_i$ given spread $\sigma_i$.

We could assume that each school's true effect size $\theta_i$ is entirely independent of any other. In contrast, we could assume that there is a single true effect size for all schools $\theta_i = \theta_j$ for all $i$ and $j$. Or, more reasonably, we let the data decide and consider a model that tries to estimate how likely it is that $\theta_i$ and $\theta_j$ for different schools $i$ and $j$ are similar or not. 

To do so, we assume a hierarchical model. The true effect sizes $\theta_i$ and $\theta_j$ of schools $i$ and $j$ are assumed:

1. to have played a role in (stochastically) generating the observed $y_i$ and $y_j$, and
2. to be themselves (stochastically) generated by (a hierarchical) process that generates (and thereby possibly assimilates) the values of $\theta_i$ and $\theta_j$.

Concretely, the model takes the following form:

$$
\begin{align*}
y_i & \sim \mathcal{N}(\theta_i, \sigma_i) \\
\theta_i & \sim \mathcal{N}(\mu, \sigma') \\
\mu & \sim \mathcal{N}(0, 10) \\
\sigma & \sim \text{half-Cauchy}(0, 10) \\
\end{align*}
$$

## 3.a Draw the model

Draw a graphical representation of this mixture model, following the conventions outlined [here](https://michael-franke.github.io/intro-data-analysis/Chap-03-03-models-representation.html). Again, any format which we can decipher easily is fine, as long as it is practical (and fun) for you.

![3.a](/Users\User\Desktop\ex3a.jpg)

## 3.b Run the model, inspect and explain the divergent transitions

The Stan code for this model is shown below and also included in file `ADA-W09-Ex3a-8schools-centered.stan`. 

```{stan, output.var="Ex3a-8schoolsCentered", eval = F}
data {
  int<lower=0> N;
  vector[N] y;
  vector<lower=0>[N] sigma;
}
parameters {
  real mu;
  real<lower=0> sigma_prime;
  vector[N] theta;
}
model {
  mu ~ normal(0, 10);
  sigma_prime ~ cauchy(0, 10);
  theta ~ normal(mu, sigma_prime);
  y ~ normal(theta, sigma);
}
```

```{r, results="hide", eval = T, warnings = T}
stan_fit_3a_8schoolsC <- stan(
  file = 'ADA-W09-Ex3a-8schools-centered.stan',
  data = data_eight_schools,
  seed = 1969
)
```

Normally, there are a lot of divergent transitions when you run this code:

```{r}
get_divergent_iterations(stan_fit_3a_8schoolsC) %>% sum()
```

Let's go explore these divergent transitions using `shinystan`. Execute the command below, go to the tab "Explore" in the Shiny App, select "Bivariate" and explore plots of $\sigma'$ against $\theta_i$ for different $i$. Points that experienced divergent transitions are shown in red. 

```{r, eval = F}
shinystan::launch_shinystan(stan_fit_3a_8schoolsC)
```

You can also produce your own (funnel) plots with the code shown below, which may be even clearer because it uses a log-transform. Again, points with divergencies are shown in red. 

```{r}
 mcmc_scatter(
  as.array(stan_fit_3a_8schoolsC),
  pars = c("theta[1]", "sigma_prime"),
  transform = list(sigma_prime = "log"),
  np = nuts_params(stan_fit_3a_8schoolsC),
  size = 1
)
```

Explain in your own intuitive terms why these divergent transitions occur. E.g., you might want to say something like: "Since the step size parameter is ..., we see divergencies ... because the more ... this variable is, the more/less ... that variable ..."

**Solution:**

<span style = "color:firebrick"> Since the step size parameter is comparatively large, we see divergencies from the true values because the larger the step size, the possibility that the estimated data point can be far away from the true path/value increases.</span>

## 3.c Non-centered parameterization

An alternative model, with so-called non-central parameterization does not have this problem with divergent transitions (they can still occur occasionally, though).

This non-central model can be written like so:

$$
\begin{align*}
y_i & \sim \mathcal{N}(\theta_i, \sigma_i) \\
\theta_i & = \mu + \sigma' \eta_i \\
\eta_i & \sim \mathcal{N}(0, 1) \\
\mu & \sim \mathcal{N}(0, 10) \\
\sigma & \sim \text{half-Cauchy}(0, 10) \\
\end{align*}
$$

Implement and run this model in Stan. Report if you got any divergent transitions, e.g., with command `get_divergent_iterations` applied to the `stanfit` object. Store the results in variable `stan_fit_3c_8schoolsNC`.

**Solution:**
```{stan, output.var="Ex3a-8schoolsnCentered", eval = F}
data {
  int<lower=0> N;
  vector[N] y;
  vector<lower=0>[N] sigma;
}
parameters {
  real mu;
  real<lower=0> sigma_prime;
  vector[N] theta;
}
transformed parameters {
  vector [N] alpha;
  for (i in 1:N){
       alpha[i]= mu + sigma_prime * theta[i];}
}
model {
  mu ~ normal(0, 10);
  sigma_prime ~ cauchy(0, 10);
  theta ~ normal(0, 1);
  y ~ normal(theta, sigma);
}
```

```{r, results="hide", eval = T, warnings = T}
stan_fit_3c_8schoolsNC <- stan(
  file = 'ADA-W09-Ex3c-8schools-noncentered.stan',
  data = data_eight_schools,
  seed = 1969
)
```

Normally, there are a lot of divergent transitions when you run this code:

```{r}
get_divergent_iterations(stan_fit_3c_8schoolsNC) %>% sum()
```




## 3.d Explain non-central parameterization

Let's look at a plot similar to the one we looked at for the model with central parameterization in 3.b:

```{r, eval = F}
 mcmc_scatter(
  as.array(stan_fit_3c_8schoolsNC),
  pars = c("theta[1]", "sigma_prime"),
  transform = list(sigma_prime = "log"),
  np = nuts_params(stan_fit_3c_8schoolsNC),
  size = 1
)
```

What is the main striking difference (apart from the presence/absence of divergent transitions)? How is this difference a reason for why divergent transitions can be problematic? Is any estimated posterior mean for any parameter noticeably affected by this?

**Solution:**

<span style = "color:firebrick"> Divergent transitions are problematic as the stimulated path departs from the actual true path. So everytime we have a divergent transitions and we do not correct it we will have to reimplement the model. If we recorrect the transition and the model runs again to fine the stimulation approximating to the true values the model can yield accurate inference. As we see in the graph the estimated mean of theta[1] is noticeably affected. </span>




